{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da7a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 17772, Val: 1000, Test: 1000\n"
     ]
    }
   ],
   "source": [
    "# Q1: Data Splitting\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Open tokenized_bengali.txt and read all lines into sentences. Each line is a sentence.\n",
    "with open(\"tokenized_bengali.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "# function to randomly split the corpus into validation, test, and training sets.\n",
    "def split_data(corpus, val_size=1000, test_size=1000):\n",
    "    random.shuffle(corpus)\n",
    "    val = corpus[:val_size]\n",
    "    test = corpus[val_size:val_size+test_size]\n",
    "    train = corpus[val_size+test_size:]\n",
    "    return train, val, test\n",
    "\n",
    "# Split the data and print the sizes of each set.\n",
    "train, val, test = split_data(sentences)\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474f1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Build N-gram Models + Good-Turing Smoothing\n",
    "\n",
    "def get_ngrams(sentences, n):\n",
    "    ngrams = []\n",
    "    for sent in sentences:\n",
    "        # For each sentence, add start (<s>) and end (</s>) tokens, then extract all n-grams.\n",
    "        tokens = [\"<s>\"]*(n-1) + sent.strip().split() + [\"</s>\"]\n",
    "        ngrams.extend([tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)])\n",
    "    return ngrams\n",
    "\n",
    "\"\"\"\n",
    "Apply Good-Turing smoothing to n-gram counts:\n",
    "counts: raw n-gram counts\n",
    "N: total n-grams\n",
    "Nc: how many n-grams have count c\n",
    "Nc[0]: number of unseen n-gram\n",
    "Cstar: adjusted counts using Good-Turing formula\n",
    "Good-Turing formula: C* = (c+1) * (Nc+1 / Nc)\n",
    "\"\"\"\n",
    "def good_turing_smoothing(ngrams, V, n):\n",
    "    counts = Counter(ngrams)\n",
    "    N = sum(counts.values())\n",
    "    Nc = Counter(counts.values())\n",
    "\n",
    "    # unseen n-grams count\n",
    "    Nc[0] = (V**n - len(counts))\n",
    "\n",
    "    # compute adjusted counts\n",
    "    Cstar = {}\n",
    "    max_c = max(counts.values())\n",
    "    for c in range(max_c+1):\n",
    "        if Nc[c] > 0 and Nc[c+1] > 0:\n",
    "            Cstar[c] = (c+1) * (Nc[c+1]/Nc[c])\n",
    "        else:\n",
    "            Cstar[c] = c  # fallback\n",
    "    return counts, Nc, Cstar, N\n",
    "\n",
    "# Calculate the probability of a sentence using Good-Turing smoothed n-gram probabilities.\n",
    "def prob_sentence(sentence, counts, Nc, Cstar, N, V, n):\n",
    "    tokens = [\"<s>\"]*(n-1) + sentence.strip().split() + [\"</s>\"]\n",
    "    ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    logprob = 0.0\n",
    "    for ng in ngrams:\n",
    "        c = counts[ng]\n",
    "        if ng in counts:\n",
    "            cstar = Cstar.get(c, c)\n",
    "            prob = cstar / N\n",
    "        else:  # unseen\n",
    "            prob = (Nc[1]/N) / (V**n - N)\n",
    "        logprob += math.log(prob + 1e-12)\n",
    "    return math.exp(logprob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a51d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C (MLE)              Nc            C*\n",
      "0         0  49386428728350  4.252646e-09\n",
      "1         1          210023  7.398237e-02\n",
      "2         2            7769  7.711417e-01\n",
      "3         3            1997  1.710566e+00\n",
      "4         4             854  2.634660e+00\n",
      "5         5             450  4.080000e+00\n",
      "6         6             306  4.140523e+00\n",
      "7         7             181  6.762431e+00\n",
      "8         8             153  6.000000e+00\n",
      "9         9             102  8.039216e+00\n",
      "10       10              82  9.390244e+00\n",
      "11       11              70  9.257143e+00\n",
      "12       12              54  1.251852e+01\n",
      "13       13              52  8.076923e+00\n",
      "14       14              30  1.800000e+01\n",
      "15       15              36  1.066667e+01\n",
      "16       16              24  1.558333e+01\n",
      "17       17              22  1.554545e+01\n",
      "18       18              19  1.300000e+01\n",
      "19       19              13  1.230769e+01\n"
     ]
    }
   ],
   "source": [
    "# Q3: Frequency Table (Top 100)\n",
    "\n",
    "def make_table(Nc, Cstar, top=100):\n",
    "    rows = []\n",
    "    for c in sorted(Nc.keys())[:top]:\n",
    "        rows.append({\"C (MLE)\": c, \"Nc\": Nc[c], \"C*\": Cstar.get(c, 0)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# for trigram\n",
    "\"\"\"\n",
    "Build trigram model from training data, apply Good-Turing smoothing, and print the top 20 rows of the frequency table.\n",
    "\"\"\"\n",
    "V = len(set(\" \".join(train).split()))\n",
    "ngrams = get_ngrams(train, 3)\n",
    "counts, Nc, Cstar, N = good_turing_smoothing(ngrams, V, n=3)\n",
    "\n",
    "df = make_table(Nc, Cstar, top=100)\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7975b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Turing (Trigram): 1.0854448866229395e-60\n",
      "Deleted Interpolation (Quadrigram): 1.3111768278573298e-41\n"
     ]
    }
   ],
   "source": [
    "# Q4: Deleted Interpolation (Quadrigram Model)\n",
    "\n",
    "def deleted_interpolation(train):\n",
    "    return [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "def prob_sentence_interpolated(sentence, train, V):\n",
    "    unigrams = Counter(get_ngrams(train,1))\n",
    "    bigrams  = Counter(get_ngrams(train,2))\n",
    "    trigrams = Counter(get_ngrams(train,3))\n",
    "    quads    = Counter(get_ngrams(train,4))\n",
    "\n",
    "    lambdas = deleted_interpolation(train)\n",
    "\n",
    "    tokens = [\"<s>\"]*3 + sentence.strip().split() + [\"</s>\"]\n",
    "    ngrams = [tuple(tokens[i:i+4]) for i in range(len(tokens)-3)]\n",
    "    logprob = 0.0\n",
    "\n",
    "    for q in ngrams:\n",
    "        w1,w2,w3,w4 = q\n",
    "        total_uni = sum(unigrams.values())\n",
    "        total_bi = sum(bigrams.values())\n",
    "        total_tri = sum(trigrams.values())\n",
    "        total_quad = sum(quads.values())\n",
    "\n",
    "        p1 = unigrams[(w4,)]/total_uni if total_uni>0 else 0\n",
    "        p2 = bigrams[(w3,w4)]/total_bi if total_bi>0 else 0\n",
    "        p3 = trigrams[(w2,w3,w4)]/total_tri if total_tri>0 else 0\n",
    "        p4 = quads[q]/total_quad if total_quad>0 else 0\n",
    "\n",
    "        prob = lambdas[0]*p1 + lambdas[1]*p2 + lambdas[2]*p3 + lambdas[3]*p4\n",
    "        logprob += math.log(prob + 1e-12)\n",
    "\n",
    "    return math.exp(logprob)\n",
    "\n",
    "# Example\n",
    "example_sentence = \"this is a test\"\n",
    "print(\"Good Turing (Trigram):\", prob_sentence(example_sentence, counts, Nc, Cstar, N, V, 3))\n",
    "print(\"Deleted Interpolation (Quadrigram):\", prob_sentence_interpolated(example_sentence, train, V))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
